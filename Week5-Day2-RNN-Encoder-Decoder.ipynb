{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN - Encoder-Decoder Model\n",
    "\n",
    "## Toy-Project: Simple Calculator using RNN\n",
    "\n",
    "- input:\n",
    "\n",
    "        '1','5','5', '+', '3','3','9'\n",
    "\n",
    "\n",
    "- output:\n",
    "\n",
    "        '4', '9', '3', ' ', ' '\n",
    "  \n",
    "\n",
    "- 입력은 숫자 두 개에 대한 연산식\n",
    "\n",
    "- 출력은 연산 결과 문자열\n",
    "\n",
    "- 입력 숫자는 각각 1~3 자리로서, 전체 수식은 연산자 포함해서 최대 7자\n",
    "\n",
    "- 출력 숫자는 1~4 자리인데, END 표시로 사용하는 `' '` 문자 포함해서 최대 5자\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN, Encoder/Decoder\n",
    "\n",
    "<img  src=\"20160120182108205.jpg\" style=\"width:55.0rem\"/>\n",
    "\n",
    "<div style=\"text-align:center\">이미지 출처: http://www.voidcn.com/article/p-virvaiso-zw.html</div>\n",
    "\n",
    "\n",
    "<img src=\"68747.jpg\" style=\"width:55.0rem\">\n",
    "\n",
    "<div style=\"text-align:center\">이미지 출처: https://github.com/guillaume-chevalier/seq2seq-signal-prediction</div>\n",
    "\n",
    "\n",
    "### Encoder/Decoder - Inference\n",
    "\n",
    "- 수식이 encoder 쪽에 들어오면, encoder 는 _**계산**_ 을 해서 그 결과를 state 로 기억\n",
    "- decoder 쪽에 START 문자 (`'='`) 가 입력되고 decoder 가 시작되면, encoder 의 state 를 받아 초기 상태로 사용하면서 state 가 표현하려는 결과를 다시 숫자열로 출력\n",
    "\n",
    "### Encoder/Decoder - Training\n",
    "\n",
    "- 입력할 수식, 출력할 숫자열을 훈련데이터로 제시\n",
    "- 출력할 숫자열은 sequence-to-sequence 방식으로 훈련\n",
    "  - decoder 입력으로는 `'='` 문자를 앞에 붙인 출력 숫자열 제시\n",
    "  - decoder 출력으로는 `' '` 문자 (END) 를 뒤에 붙인 수식을 제시\n",
    "  - decoder 입력-출력 pair 를 하나씩 보면, 앞 자리의 숫자를 입력하면 현재 자리의 숫자를 출력하는 RNN을 학습하는 것이 됨\n",
    "  \n",
    "  \n",
    "```\n",
    "                                                 decoder outputs\n",
    "\n",
    "                                                5   7   9   \n",
    "        +---+---+---+---+---+---+---+         +---+---+---+---+\n",
    "encoder |   |   |   |   |   |   |   +---------+   |   |   |   | decoder\n",
    "        +---+---+---+---+---+---+---+         +---+---+---+---+\n",
    "\n",
    "          1   2   3   +   4   5   6             =   5   7   9\n",
    "\n",
    "              encoder inputs                     decoder inputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:28.712517Z",
     "start_time": "2017-10-11T01:45:28.480479Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -fr logdir2\n",
    "!mkdir -p logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.370534Z",
     "start_time": "2017-10-11T01:45:28.713749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@media print {\n",
       "  a[href]:after {\n",
       "    content: none !important;\n",
       "  }\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext do_not_print_href\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set - symbols & symbol map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력/출력 문자는 0~9 까지의 숫자, 연산자 `'+'`, `' '` (END), `'='` (START) 포함하여 13 종류\n",
    "\n",
    "- 사용가능한 연산자는 `'+'`\n",
    "\n",
    "- 문자(symbol) 와 해당 문자의 인덱스 넘버 사이의 변환을 위한 배열/사전 준비\n",
    "\n",
    "  - `symbols[]`    : 인덱스에서 문자로\n",
    "  - `symbol_map[]` : 문자에서 인덱스로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.380376Z",
     "start_time": "2017-10-11T01:45:29.374030Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbols        = [' ', '0', '1', '2', '3', '4', '5',\n",
    "                  '6', '7', '8', '9', '+', '=']\n",
    "operators      = ['+']\n",
    "\n",
    "symbol_map     = {s: i \\\n",
    "                  for i,s in enumerate(symbols)}\n",
    "input_units    = output_units    = len(symbol_map)\n",
    "hidden_units   = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.393602Z",
     "start_time": "2017-10-11T01:45:29.381594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol_map = {' ': 0, '+': 11, '1': 2, '0': 1, '3': 4, '2': 3, '5': 6, '4': 5, '7': 8, '6': 7, '9': 10, '8': 9, '=': 12}\n"
     ]
    }
   ],
   "source": [
    "print('symbol_map =',symbol_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set - Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.402041Z",
     "start_time": "2017-10-11T01:45:29.396723Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_random_data():\n",
    "    t1        = str(np.random.randint(1000))\n",
    "    op        = np.random.choice(operators)\n",
    "    t2        = str(np.random.randint(1000))\n",
    "    \n",
    "    expr      = t1 + op + t2\n",
    "    ans       = '='+str(eval(expr))+' '\n",
    "    \n",
    "    return expr, ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.414660Z",
     "start_time": "2017-10-11T01:45:29.403871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['6', '+', '7', '3', '4'], ['=', '7', '4', '0', ' '])\n",
      "(['5', '0', '6', '+', '7', '4', '3'], ['=', '1', '2', '4', '9', ' '])\n",
      "(['5', '8', '0', '+', '5', '7', '4'], ['=', '1', '1', '5', '4', ' '])\n",
      "(['7', '9', '1', '+', '3', '7', '3'], ['=', '1', '1', '6', '4', ' '])\n",
      "(['9', '4', '1', '+', '3', '4', '3'], ['=', '1', '2', '8', '4', ' '])\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    expr, ans = make_random_data()\n",
    "    print(([c for c in expr], [c for c in ans]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set - one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.425767Z",
     "start_time": "2017-10-11T01:45:29.416048Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(n):\n",
    "    \"\"\"\n",
    "    3 ==> [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \"\"\"\n",
    "    res = np.zeros(13, dtype=np.float32)\n",
    "    res[n] = 1.0\n",
    "    return res\n",
    "\n",
    "def arg_max(v):\n",
    "    \"\"\"\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] ==> 3\n",
    "    \"\"\"\n",
    "    return np.argmax(v, axis=-1)\n",
    "\n",
    "# test\n",
    "assert 7 == arg_max(one_hot(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.435656Z",
     "start_time": "2017-10-11T01:45:29.428663Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_max_seq_len = 7\n",
    "decoder_max_seq_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.448895Z",
     "start_time": "2017-10-11T01:45:29.436987Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_onehot(str, max_seq_len):\n",
    "    buf           = np.zeros([max_seq_len,input_units])\n",
    "    buf          += \\\n",
    "      one_hot(symbol_map[' ']).reshape([1,-1]) # <<<===\n",
    "    seq_len       = len(str)\n",
    "    buf[:seq_len] = [one_hot(symbol_map[c]) for c in str]\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.461386Z",
     "start_time": "2017-10-11T01:45:29.450114Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_to_str(data, data_len):\n",
    "    return ''.join([symbols[v] \\\n",
    "                    for v in arg_max(data)][:data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.470585Z",
     "start_time": "2017-10-11T01:45:29.465736Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_data(expr, ans):\n",
    "    e_seq_len         = len(expr)\n",
    "    e_in              = str_to_onehot(expr,\n",
    "                                      encoder_max_seq_len)\n",
    "    d_seq_len         = len(ans) - 1\n",
    "    d_in              = str_to_onehot(ans[:-1],\n",
    "                                      decoder_max_seq_len)\n",
    "    d_out             = str_to_onehot(ans[1:],\n",
    "                                      decoder_max_seq_len)\n",
    "    return e_seq_len, e_in, d_seq_len, d_in, d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.479701Z",
     "start_time": "2017-10-11T01:45:29.473777Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_data(e_len, e_in, d_len, d_in, d_out):\n",
    "    return  e_len, \\\n",
    "            onehot_to_str(e_in, e_len), \\\n",
    "            d_len, \\\n",
    "            onehot_to_str(d_in, d_len), \\\n",
    "            onehot_to_str(d_out, d_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.489420Z",
     "start_time": "2017-10-11T01:45:29.481005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, '399+997', 5, '=1396', '1396 ')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_data(*encode_data(*make_random_data()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set: create data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.501075Z",
     "start_time": "2017-10-11T01:45:29.491750Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:29.512670Z",
     "start_time": "2017-10-11T01:45:29.502266Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num_data = 60000\n",
    "test_num_data  = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.319507Z",
     "start_time": "2017-10-11T01:45:29.513932Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# common data format\n",
    "# e_len, e_in, d_len, d_in, d_out\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.encoder_seq_len  = []\n",
    "        self.encoder_in_data  = []\n",
    "        self.decoder_seq_len  = []\n",
    "        self.decoder_in_data  = []\n",
    "        self.decoder_out_data = []\n",
    "        \n",
    "    def append(self, t):\n",
    "        self.encoder_seq_len.append(t[0])\n",
    "        self.encoder_in_data.append(t[1])\n",
    "        self.decoder_seq_len.append(t[2])\n",
    "        self.decoder_in_data.append(t[3])\n",
    "        self.decoder_out_data.append(t[4])\n",
    "        \n",
    "    def next_batch(self,batch_size=BATCH_SIZE):\n",
    "        data_len = len(self.encoder_seq_len)\n",
    "        batch_pointer = 0\n",
    "        while batch_pointer + batch_size <= data_len:\n",
    "            ss   = np.random.randint(\n",
    "                data_len - batch_size - 1)\n",
    "            yield \\\n",
    "                self.encoder_seq_len[ss:ss+batch_size], \\\n",
    "                self.encoder_in_data[ss:ss+batch_size], \\\n",
    "                self.decoder_seq_len[ss:ss+batch_size], \\\n",
    "                self.decoder_in_data[ss:ss+batch_size], \\\n",
    "                self.decoder_out_data[ss:ss+batch_size]\n",
    "            batch_pointer += batch_size\n",
    "\n",
    "\n",
    "np.random.seed(37L)\n",
    "\n",
    "train_data = Dataset()\n",
    "for i in range(train_num_data):\n",
    "    expr, ans     = make_random_data()\n",
    "    train_data.append(encode_data(expr, ans))\n",
    "\n",
    "test_data  = Dataset()\n",
    "for i in range(test_num_data):\n",
    "    expr, ans     = make_random_data()\n",
    "    test_data.append(encode_data(expr, ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set: data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print & verify first training data\n",
    "\n",
    "- `next_batch()` 는 `for` 문장과 함께 쓰일 수 있음.\n",
    "- `next_batch()` 가 `for` 문장과 함께 쓰지지 않는 경우는 다시 next() 를 호출해야 함. (python interator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.327669Z",
     "start_time": "2017-10-11T01:45:33.321357Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, '756+55', 4, '=811', '811 ')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_len,e_in,d_len,d_in,d_out = train_data.next_batch().next()\n",
    "decode_data(e_len[0],e_in[0],d_len[0],d_in[0],d_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.340346Z",
     "start_time": "2017-10-11T01:45:33.331423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, '269+927', 5, '=1196', '1196 ')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_data(e_len[1],e_in[1],d_len[1],d_in[1],d_out[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow - build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.345533Z",
     "start_time": "2017-10-11T01:45:33.343653Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow - placeholders & dynamic batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.385906Z",
     "start_time": "2017-10-11T01:45:33.346950Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs   = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, encoder_max_seq_len, input_units],\n",
    "    name='encoder_inputs')\n",
    "encoder_seqlen   = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=[None],\n",
    "    name='encoder_seqlen')\n",
    "decoder_inputs   = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, decoder_max_seq_len, input_units],\n",
    "    name='decoder_inputs')\n",
    "decoder_targets  = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, decoder_max_seq_len, output_units],\n",
    "    name='decoder_targets')\n",
    "decoder_seqlen   = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=[None],\n",
    "    name='decoder_seqlen')\n",
    "encoder_training = tf.placeholder(\n",
    "    dtype=tf.bool,\n",
    "    shape=None,\n",
    "    name='encoder_training')\n",
    "tf_batch_size = tf.shape(encoder_inputs)[0] # <<== !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.401416Z",
     "start_time": "2017-10-11T01:45:33.387467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN, Encoder/Decoder - 2-Layers, with Dropouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [`tf.cond()`](http://devdocs.io/tensorflow~python/tf/cond)\n",
    "> Return true_fn() if the predicate pred is true else false_fn()\n",
    "\n",
    "```\n",
    "cond(\n",
    "    pred,\n",
    "    true_fn=None,\n",
    "    false_fn=None,\n",
    "    strict=False,\n",
    "    name=None,\n",
    "    fn1=None,\n",
    "    fn2=None\n",
    ")\n",
    "```\n",
    "\n",
    "- `true_fn`, `false_fn` 에는 [lambda expression](https://docs.python.org/2.7/reference/expressions.html#lambda) 이 종종 사용됨\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:33.409312Z",
     "start_time": "2017-10-11T01:45:33.403593Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "keep_prob = tf.cond(encoder_training,\n",
    "                    lambda: tf.constant(1.0-dropout_rate),\n",
    "                    lambda: tf.constant(1.0),\n",
    "                    name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [`tf.contrib.rnn.DropoutWrapper`](http://devdocs.io/tensorflow~python/tf/contrib/rnn/dropoutwrapper)\n",
    "\n",
    "<code>\n",
    "    `__init__`(\n",
    "        <span style=\"color:red\">cell,</span>\n",
    "        input_keep_prob=1.0,\n",
    "        output_keep_prob=1.0,\n",
    "        state_keep_prob=1.0,\n",
    "        <span style=\"color:red\">variational_recurrent=False,</span>\n",
    "        input_size=None,\n",
    "        dtype=None,\n",
    "        seed=None\n",
    "    )\n",
    "</code>\n",
    "\n",
    "\n",
    "- `dropout_prob` 이 아니라 `keep_prob` 를 적어주는 점에 유의\n",
    "\n",
    "- `input_keep_prob`, `output_keep_prob`, `state_keep_prob` 로 구분하여 적용\n",
    "\n",
    "- `variational_recurrent` 플래그 (**_tensorflow_** 1.1 부터 지원)\n",
    "\n",
    "  - [A Theorerically Grounded Application of Dropout in Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\n",
    "\n",
    "  - RNN의 경우, 훈련데이터에 overfitting 하는 경향이 심한데, 일반적인 dropout 방식을 사용해도 효과가 없더라\n",
    "  \n",
    "  - Bayesian interpretation 으로 dropout 기법에 대해서 분석해 본 결과 RNN 에 적용 가능한 새로운 dropout 기법을 개발\n",
    "\n",
    "\n",
    "- [`tf.contrib.rnn.LayerNormBasicLSTMCell`](http://devdocs.io/tensorflow~python/tf/contrib/rnn/layernormbasiclstmcell) 에는 자체 [_recurrent dropout_](https://arxiv.org/abs/1603.05118) 지원 기능이 있음\n",
    "\n",
    "```\n",
    "    __init__(\n",
    "        num_units,\n",
    "        forget_bias=1.0,\n",
    "        input_size=None,\n",
    "        activation=tf.tanh,\n",
    "        layer_norm=True,\n",
    "        norm_gain=1.0,\n",
    "        norm_shift=0.0,\n",
    "        dropout_keep_prob=1.0,\n",
    "        dropout_prob_seed=None,\n",
    "        reuse=None\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> BasicRNNCell, BasicLSTMCell, GRUCell 모두 state 의 형태가 다르다 </span>\n",
    "\n",
    "#### cell initial state 를 생성하기 위해서는 [`cell.zero_state()`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/RNNCell#zero_state) 메소드 사용\n",
    "\n",
    "<code>\n",
    "    zero_state(\n",
    "        batch_size,\n",
    "        dtype\n",
    "    )\n",
    "</code>\n",
    "\n",
    "- batch_size: int, float, or <span style=\"color:red\">unit Tensor</span> representing the batch size.\n",
    "\n",
    "- dtype: the data type to use for the state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-RNN 과 Decoder-RNN 은 `initial_state` 를 통해서 연결된다\n",
    "\n",
    "- Encoder-RNN\n",
    "<code>\n",
    "    encoder_out, <span style=\"color:red\">encoder_state</span> = tf.nn.dynamic_rnn(...)\n",
    "</code>\n",
    "\n",
    "\n",
    "- DecoderRNN\n",
    "<code>\n",
    "    decoder_out, decoder_state = tf.nn.dynamic_rnn(... <span style=\"color:red\">initial_state=encoder_state</span>)\n",
    "</code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.279454Z",
     "start_time": "2017-10-11T01:45:33.411152Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder RNN\n",
    "\n",
    "def e_cell(input_size):\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LSTMCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LayerNormBasicLSTMCell(\n",
    "#              hidden_units)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        cell,\n",
    "        state_keep_prob = keep_prob,\n",
    "        variational_recurrent = True,\n",
    "        input_size = input_size,\n",
    "        dtype = tf.float32)\n",
    "    return cell\n",
    "\n",
    "with tf.variable_scope('encoder'):\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(\n",
    "        [\n",
    "            e_cell(input_units),\n",
    "            e_cell(hidden_units),\n",
    "            e_cell(hidden_units)\n",
    "        ])\n",
    "    initial_state = cell.zero_state(\n",
    "        batch_size=tf_batch_size,\n",
    "        dtype=tf.float32)\n",
    "    encoder_out, encoder_state = tf.nn.dynamic_rnn(\n",
    "        cell,\n",
    "        encoder_inputs,\n",
    "        sequence_length=encoder_seqlen,\n",
    "        initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.359677Z",
     "start_time": "2017-10-11T01:45:34.280682Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decoder RNN\n",
    "def d_cell():\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LSTMCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LayerNormBasicLSTMCell(\n",
    "#              hidden_units)\n",
    "    return cell\n",
    "\n",
    "with tf.variable_scope('decoder'):\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(\n",
    "        [d_cell() for _ in range(3)])\n",
    "    initial_state = encoder_state # <<<==== \n",
    "    decoder_out, decoder_state = tf.nn.dynamic_rnn(\n",
    "        cell,\n",
    "        decoder_inputs,\n",
    "        sequence_length=decoder_seqlen,\n",
    "        initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.365887Z",
     "start_time": "2017-10-11T01:45:34.360977Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 7, 100]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_out.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.374602Z",
     "start_time": "2017-10-11T01:45:34.367079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 5, 100]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out.shape.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Network after RNN\n",
    "\n",
    "- 5주 1일차에 사용한 코드는 이렇지만,\n",
    "\n",
    "\n",
    "<div  style=\"width:45.0rem;margin:auto;border:1px solid black;border-radius:3px\">\n",
    "<code>\n",
    "        # 10 개의 output units 로 만들 \n",
    "        #  FCN (fully-connected-network) 구성\n",
    "        # outputs shape will become: [batch_size, 10]\n",
    "        <span style=\"color:red\">outputs    = tf.layers.dense(rnn_output, 10)</span>\n",
    "\n",
    "</code>\n",
    "</div>\n",
    "\n",
    "- 이번에는 `tf.nn.xw_plus_b()` 를 이용해서 만들어 봅니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.395408Z",
     "start_time": "2017-10-11T01:45:34.376754Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_w    = tf.get_variable(\n",
    "                \"output_w\",\n",
    "                [hidden_units, output_units])\n",
    "output_b    = tf.get_variable(\n",
    "                \"output_b\",\n",
    "                [output_units])\n",
    "\n",
    "# xw_plus_b() 는 2D 텐서만 처리할 수 있음\n",
    "decoder_o_  = tf.reshape(decoder_out,\n",
    "                         [-1, hidden_units])\n",
    "outputs_    = tf.nn.xw_plus_b(decoder_o_,\n",
    "                              output_w,\n",
    "                              output_b)\n",
    "# xw_plus_b() 를 위해 변형했던 것 처럼 출력을 다시 원 형태로 원복\n",
    "outputs     = tf.reshape(\n",
    "                outputs_,\n",
    "                [-1, decoder_max_seq_len, output_units])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.399472Z",
     "start_time": "2017-10-11T01:45:34.396688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 5, 13]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.486625Z",
     "start_time": "2017-10-11T01:45:34.400676Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_config = tf.ConfigProto(\n",
    "    allow_soft_placement=True,\n",
    "    gpu_options={'allow_growth': True})\n",
    "sess = tf.InteractiveSession(config=tf_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.668287Z",
     "start_time": "2017-10-11T01:45:34.487881Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.856848Z",
     "start_time": "2017-10-11T01:45:34.669578Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e_len, e_in, d_len, d_in, d_out = \\\n",
    "    train_data.next_batch().next()\n",
    "feed = {\n",
    "    encoder_training: False,\n",
    "    encoder_seqlen: e_len,\n",
    "    encoder_inputs: e_in,\n",
    "    decoder_seqlen: d_len,\n",
    "    decoder_inputs: d_in,\n",
    "    decoder_targets: d_out,\n",
    "}\n",
    "out = sess.run(outputs, feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.863270Z",
     "start_time": "2017-10-11T01:45:34.858235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  9, 10, 11,  5,  5,  3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_max(e_in[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.878447Z",
     "start_time": "2017-10-11T01:45:34.864865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, '789+442', 5, '=1231', '1231 ')\n",
      "(7, '253+889', 5, '=1142', '1142 ')\n",
      "(7, '531+142', 4, '=673', '673 ')\n",
      "(6, '745+69', 4, '=814', '814 ')\n",
      "(7, '576+728', 5, '=1304', '1304 ')\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(decode_data(e_len[i],e_in[i],d_len[i],d_in[i],d_out[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare training target vs output\n",
    "\n",
    "- handling sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.895467Z",
     "start_time": "2017-10-11T01:45:34.879844Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_mask_ = tf.sequence_mask(\n",
    "                decoder_seqlen,\n",
    "                maxlen=decoder_max_seq_len,\n",
    "                dtype=tf.float32)\n",
    "\n",
    "seq_mask     = \\\n",
    "    tf.tile(\n",
    "        tf.reshape(\n",
    "            seq_mask_,\n",
    "            [-1,decoder_max_seq_len,1]),\n",
    "        [1,1,output_units])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.918421Z",
     "start_time": "2017-10-11T01:45:34.896864Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_seq_mask_,a_seq_mask = sess.run(\n",
    "    [\n",
    "        seq_mask_,\n",
    "        seq_mask,\n",
    "    ],\n",
    "    {decoder_seqlen: [1,2,3,4,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.928262Z",
     "start_time": "2017-10-11T01:45:34.919877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  0.],\n",
       "       [ 1.,  1.,  1.,  1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_seq_mask_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.938073Z",
     "start_time": "2017-10-11T01:45:34.929613Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_seq_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:34.976555Z",
     "start_time": "2017-10-11T01:45:34.939458Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss         = tf.losses.softmax_cross_entropy(\n",
    "                    decoder_targets * seq_mask,\n",
    "                    outputs * seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.446179Z",
     "start_time": "2017-10-11T01:45:34.978409Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer    = tf.train.AdamOptimizer( \\\n",
    "                  learning_rate=0.001)\n",
    "optimize     = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.489016Z",
     "start_time": "2017-10-11T01:45:35.447288Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer가 새로 변수를 만들었을 것이므로\n",
    "# 변수 초기화를 다시 해야 함\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.562258Z",
     "start_time": "2017-10-11T01:45:35.490377Z"
    },
    "cell_style": "center",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e_len, e_in, d_len, d_in, d_out = \\\n",
    "    train_data.next_batch().next()\n",
    "feed = {\n",
    "    encoder_training: True,\n",
    "    encoder_seqlen:   e_len,\n",
    "    encoder_inputs:   e_in,\n",
    "    decoder_seqlen:   d_len,\n",
    "    decoder_inputs:   d_in,\n",
    "    decoder_targets:  d_out,\n",
    "}\n",
    "_, out, loss_value = \\\n",
    "    sess.run([optimize, outputs, loss], feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.570554Z",
     "start_time": "2017-10-11T01:45:35.563427Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 5, 13), (200, 5, 13), 2.444243)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(d_out).shape, out.shape, loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.581928Z",
     "start_time": "2017-10-11T01:45:35.571768Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_equals(a,b,a_len=None,b_len=None):\n",
    "    if a_len is None: a_len = len(a)\n",
    "    if b_len is None: b_len = len(b)\n",
    "    a_nums = np.argmax(a[:a_len],-1)\n",
    "    b_nums = np.argmax(b[:b_len],-1)\n",
    "    return 1.0 * np.all(np.equal(a_nums, b_nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.592312Z",
     "start_time": "2017-10-11T01:45:35.583111Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T01:45:35.619717Z",
     "start_time": "2017-10-11T01:45:35.593609Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, writer):\n",
    "    t_start = time.time()\n",
    "    step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        losses  = []\n",
    "        errs    = []\n",
    "        for e_len, e_in, d_len, d_in, d_out \\\n",
    "                in train_data.next_batch():\n",
    "            feed = {\n",
    "                encoder_training: True,\n",
    "                encoder_seqlen:   e_len,\n",
    "                encoder_inputs:   e_in,\n",
    "                decoder_seqlen:   d_len,\n",
    "                decoder_inputs:   d_in,\n",
    "                decoder_targets:  d_out,\n",
    "            }\n",
    "            _, out, training_loss = \\\n",
    "                sess.run([optimize, outputs, loss], feed)\n",
    "            training_err = 1.0 - \\\n",
    "                np.mean([\n",
    "                    seq_equals(a,b,a_len,b_len)\n",
    "                    for a,b,a_len,b_len in\n",
    "                    zip(d_out,out,d_len,d_len)\n",
    "                ])\n",
    "            losses.append(training_loss)\n",
    "            errs.append(training_err)\n",
    "        test_errs   = []\n",
    "        for e_len, e_in, d_len, d_in, d_out \\\n",
    "                in test_data.next_batch():\n",
    "            feed = {\n",
    "                encoder_training: False,\n",
    "                encoder_seqlen:   e_len,\n",
    "                encoder_inputs:   e_in,\n",
    "                decoder_seqlen:   d_len,\n",
    "                decoder_inputs:   d_in,\n",
    "                decoder_targets:  d_out,\n",
    "            }\n",
    "            out, = sess.run([outputs], feed)\n",
    "            test_err = 1.0 - \\\n",
    "                np.mean([\n",
    "                    seq_equals(a,b,a_len,b_len)\n",
    "                    for a,b,a_len,b_len in\n",
    "                    zip(d_out,out,d_len,d_len)\n",
    "                ])\n",
    "            test_errs.append(test_err)\n",
    "        mean_loss       = np.mean(losses)\n",
    "        mean_err        = np.mean(errs)\n",
    "        mean_test_err   = np.mean(test_errs)\n",
    "        summary = tf.Summary(\n",
    "            value=[\n",
    "                tf.Summary.Value(\n",
    "                    tag='loss',\n",
    "                    simple_value=mean_loss),\n",
    "                tf.Summary.Value(\n",
    "                    tag='train_err',\n",
    "                    simple_value=mean_err),\n",
    "                tf.Summary.Value(\n",
    "                    tag='test_err',\n",
    "                    simple_value=mean_test_err),\n",
    "            ])\n",
    "        writer.add_summary(summary,epoch+1)\n",
    "        if 0 == (epoch+1) % 10:\n",
    "            t_elapsed = time.time() - t_start\n",
    "            print(('epoch: {:d}, loss: {:.5f}, ' +\n",
    "                   'err: {:.5f}, test_err: {:.5f}, ' +\n",
    "                   'elapsed: {:.2f}').format(\n",
    "                epoch+1,\n",
    "                mean_loss,\n",
    "                mean_err,\n",
    "                mean_test_err,\n",
    "                t_elapsed))\n",
    "            t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.537Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\n",
    "            'logdir2/encoder_decoder',\n",
    "            tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.539Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.64533, err: 0.83135, test_err: 0.62540, elapsed: 43.96\n",
      "epoch: 20, loss: 0.49549, err: 0.71288, test_err: 0.29300, elapsed: 46.17\n",
      "epoch: 30, loss: 0.41777, err: 0.63077, test_err: 0.24930, elapsed: 47.92\n",
      "epoch: 40, loss: 0.36272, err: 0.57020, test_err: 0.23850, elapsed: 47.65\n",
      "epoch: 50, loss: 0.31261, err: 0.50530, test_err: 0.19270, elapsed: 49.39\n",
      "epoch: 60, loss: 0.28457, err: 0.46492, test_err: 0.15380, elapsed: 51.94\n",
      "epoch: 70, loss: 0.27092, err: 0.44473, test_err: 0.15490, elapsed: 43.37\n",
      "epoch: 80, loss: 0.25230, err: 0.41738, test_err: 0.11990, elapsed: 43.39\n",
      "epoch: 90, loss: 0.23550, err: 0.39090, test_err: 0.12450, elapsed: 53.69\n",
      "epoch: 100, loss: 0.22818, err: 0.37970, test_err: 0.18140, elapsed: 53.07\n"
     ]
    }
   ],
   "source": [
    "train(100, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training progress was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.541Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !tensorboard --logdir logdir2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained network - prepare test input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expr:    ['1', '2', '3', '+', '4', '5', '6']\n",
      "ans:     ['=', '5', '7', '9']\n",
      "target:  ['5', '7', '9', ' ']\n"
     ]
    }
   ],
   "source": [
    "t1, op, t2        = '123', '+', '456'\n",
    "\n",
    "expr              = t1 + op + t2\n",
    "ans               = '='+str(eval(expr))\n",
    "target            = (ans+' ')[1:]\n",
    "\n",
    "print('expr:   ',[c for c in expr])\n",
    "print('ans:    ',[c for c in ans])\n",
    "print('target: ',[c for c in target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained network - prepare test input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.545Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_encoder_input = [one_hot(symbol_map[c]) \\\n",
    "                      for c in expr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 13)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_encoder_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.], dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encoder_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test trained network - run encoder\n",
    "\n",
    "- 7 개의 입력 시퀀스를 넣음\n",
    "\n",
    "  - batch size = 1\n",
    "  \n",
    "  - `encoder_seqlen` : [7]\n",
    "\n",
    "  - `encoder_inputs` : `test_encoder_input`\n",
    "    - `'1', '2', '3', '+', '4', '5', '6'` 에 대한 인덱스 값들을 one-hot encoding\n",
    "\n",
    "  - `encoder_training` : False (dropout_rate 를 0.0 으로 설정)\n",
    "  \n",
    "- encoder 의 출력:\n",
    "\n",
    "  - `encoder_out` : encoder RNN 의 매 batch, 매 sequence 마다의 출력. **사용하지않음**\n",
    "  \n",
    "  - `encoder_state` : 입력된 연산식의 계산 결과값에 대한 _representation_ 이 들어 있다고 여겨지는 값\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.550Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed = {\n",
    "    encoder_seqlen: [encoder_max_seq_len],\n",
    "    encoder_inputs: [test_encoder_input],\n",
    "    encoder_training: False\n",
    "}\n",
    "e_out, e_state = sess.run(\n",
    "                    [encoder_out, encoder_state],\n",
    "                    feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 7, 100), tuple)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_out.shape, type(e_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained network - First Decoder Run\n",
    "\n",
    "- `answer` : 결과 값을 문자로 받기 위한 7자 버퍼\n",
    "\n",
    "- `answer` 값이 decoder의 초기 입력으로 제공됨\n",
    "\n",
    "- `answer` 값이 decoder 초기 입력이 될 때, 첫 심볼이 `'='` 이어야 함. 나머지는 don't care\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['=', ' ', ' ', ' ', ' ']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = ['='] + [c for c in '    ']\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Inputs/Outputs\n",
    "\n",
    "- `encoder_state` : 계산결과의 _representation_ 이 들어있다고 생각되는, encoder network 의 최종 상태\n",
    "\n",
    "- `decoder_seqlen` : 루프 한 스텝에서 입력할 디코더 시퀀스 길이\n",
    "    \n",
    "- `decoder_inputs` : 루프 한 스텝 분량의 디코더 입력값\n",
    "\n",
    "- `decoder_state` : decoder RNN 의 한 스텝 진행 후의 상태. 다음 스텝을 진행할 때 decoder initial state 로 제시 해야 하는 값\n",
    "\n",
    "- `decoder_out` : decoder RNN 의 직접 출력. **사용하지않음**. 이 값을 FCN 으로 보내 나오는 `outputs` 가 실제 출력\n",
    "\n",
    "- `outputs` : 최종 one-hot output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.554Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed = {\n",
    "    encoder_state: e_state,\n",
    "    decoder_seqlen: [1],\n",
    "    decoder_inputs: [[one_hot(symbol_map[c]) \\\n",
    "                      for c in answer]]\n",
    "}\n",
    "out, d_out, d_state = sess.run(\n",
    "                        [outputs,\n",
    "                         decoder_out,\n",
    "                         decoder_state],\n",
    "                        feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 5, 13), (1, 5, 100))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape, d_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_max(out[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols[arg_max(out[0,0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained network - Repeated Decoder Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.559Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digit = symbols[arg_max(out[0,0])]\n",
    "collect_answer = [digit]\n",
    "for _ in range(1,decoder_max_seq_len):\n",
    "    feed = {\n",
    "        encoder_state: d_state,\n",
    "        decoder_seqlen: [1],\n",
    "        decoder_inputs: [[one_hot(symbol_map[c]) \\\n",
    "                          for c in answer]]\n",
    "    }\n",
    "    out, d_out, d_state = \\\n",
    "        sess.run([outputs, decoder_out, decoder_state],\n",
    "                 feed)\n",
    "    digit = symbols[arg_max(out[0,0])]\n",
    "    collect_answer.append(digit)\n",
    "    answer[0] = digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '7', '9', ' ', ' ']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Wrap-up: infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.562Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer(expr):\n",
    "    # encoder\n",
    "    feed = {\n",
    "        encoder_seqlen: [len(expr)],\n",
    "        encoder_inputs: \\\n",
    "            [str_to_onehot(expr,encoder_max_seq_len)],\n",
    "        encoder_training: False\n",
    "    }\n",
    "    e_out, e_state = \\\n",
    "        sess.run([encoder_out, encoder_state], feed)\n",
    "    \n",
    "    # decoder: step 0\n",
    "    out_buf = []\n",
    "    feed = {\n",
    "        encoder_state: e_state,\n",
    "        decoder_seqlen: [1],\n",
    "        decoder_inputs: \\\n",
    "            [str_to_onehot('=',decoder_max_seq_len)]\n",
    "    }\n",
    "    out, d_state = sess.run([outputs, decoder_state], feed)\n",
    "    out_decoded = onehot_to_str(out[0],1)\n",
    "    out_buf.append(out_decoded)\n",
    "    \n",
    "    # decoder: step 1..n-1\n",
    "    for _ in range(1,decoder_max_seq_len):\n",
    "        feed = {\n",
    "            encoder_state: d_state,\n",
    "            decoder_seqlen: [1],\n",
    "            decoder_inputs: \\\n",
    "                [str_to_onehot(out_decoded,decoder_max_seq_len)]\n",
    "        }\n",
    "        out, d_state = sess.run([outputs, decoder_state], feed)\n",
    "        out_decoded = onehot_to_str(out[0],1)\n",
    "        out_buf.append(out_decoded)\n",
    "\n",
    "    return ''.join(out_buf), e_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'456  '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans, e_out = infer('345+111')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'567  '"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans, e_out = infer('345+222')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'333  '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans, e_out = infer('111+222')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.567Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[803  ] [803  ] 203+600\n",
      "[933  ] [933  ] 722+211\n",
      "[325  ] [325  ] 73+252\n",
      "[1496 ] [1496 ] 684+812\n",
      "[629  ] [629  ] 82+547\n",
      "[1162 ] [1162 ] 285+877\n",
      "[568  ] [568  ] 448+120\n",
      "[575  ] [575 1] 156+419\n",
      "[1524 ] [1524 ] 666+858\n",
      "[873  ] [873  ] 670+203\n",
      "[1386 ] [1386 ] 479+907\n",
      "[856  ] [856  ] 834+22\n",
      "[1154 ] [1154 ] 624+530\n",
      "[646  ] [645  ] 584+62\n",
      "[1244 ] [1244 ] 990+254\n",
      "[665  ] [665  ] 169+496\n",
      "[140  ] [139  ] 133+7\n",
      "[626  ] [617  ] 623+3\n",
      "[674  ] [674 1] 66+608\n",
      "[1234 ] [1234 ] 253+981\n",
      "[1016 ] [1016 ] 684+332\n",
      "[1208 ] [1208 ] 460+748\n",
      "[1100 ] [1099 ] 949+151\n",
      "[644  ] [644  ] 444+200\n",
      "[864  ] [864  ] 351+513\n",
      "[354  ] [354  ] 95+259\n",
      "[57  ] [59   ] 56+1\n",
      "[833  ] [833  ] 52+781\n",
      "[1254 ] [1254 ] 601+653\n",
      "[1099 ] [1099 ] 194+905\n",
      "[220  ] [210  ] 193+27\n",
      "[1152 ] [1152 ] 929+223\n",
      "[1119 ] [1119 ] 319+800\n",
      "[1027 ] [1027 ] 316+711\n",
      "[208  ] [208  ] 102+106\n",
      "[990  ] [980  ] 57+933\n",
      "[943  ] [943  ] 289+654\n",
      "[1376 ] [1376 ] 683+693\n",
      "[1348 ] [1348 ] 517+831\n",
      "[586  ] [586  ] 127+459\n",
      "[1210 ] [1210 ] 395+815\n",
      "[1689 ] [1689 ] 727+962\n",
      "[579  ] [579  ] 25+554\n",
      "[505  ] [505  ] 388+117\n",
      "[910  ] [910  ] 543+367\n",
      "[993  ] [993  ] 373+620\n",
      "[1388 ] [1388 ] 539+849\n",
      "[585  ] [585  ] 314+271\n",
      "[1220 ] [1220 ] 330+890\n",
      "[1256 ] [1256 ] 533+723\n",
      "[1961 ] [1950 ] 997+964\n",
      "[1209 ] [1219 ] 508+701\n",
      "[1040 ] [1040 ] 807+233\n",
      "[873  ] [873  ] 116+757\n",
      "[870  ] [860  ] 841+29\n",
      "[714  ] [714  ] 240+474\n",
      "[446  ] [446  ] 396+50\n",
      "[503  ] [503  ] 0+503\n",
      "[593  ] [593  ] 49+544\n",
      "[705  ] [705  ] 497+208\n",
      "[1862 ] [1862 ] 932+930\n",
      "[1467 ] [1467 ] 979+488\n",
      "[1783 ] [1783 ] 950+833\n",
      "[676  ] [676  ] 531+145\n",
      "[1514 ] [1514 ] 641+873\n",
      "[511  ] [511  ] 171+340\n",
      "[670  ] [670  ] 204+466\n",
      "[970  ] [970  ] 120+850\n",
      "[1006 ] [1006 ] 618+388\n",
      "[902  ] [902  ] 785+117\n",
      "[1187 ] [1187 ] 200+987\n",
      "[1050 ] [1050 ] 485+565\n",
      "[433  ] [433  ] 200+233\n",
      "[1045 ] [1045 ] 413+632\n",
      "[498  ] [498  ] 169+329\n",
      "[897  ] [897  ] 688+209\n",
      "[1066 ] [1066 ] 121+945\n",
      "[254  ] [255  ] 243+11\n",
      "[935  ] [935  ] 524+411\n",
      "[1318 ] [1327 ] 406+912\n",
      "[922  ] [922  ] 606+316\n",
      "[1125 ] [1125 ] 709+416\n",
      "[481  ] [481  ] 439+42\n",
      "[433  ] [433  ] 297+136\n",
      "[1258 ] [1258 ] 752+506\n",
      "[682  ] [682  ] 300+382\n",
      "[571  ] [571  ] 352+219\n",
      "[1490 ] [1480 ] 992+498\n",
      "[1130 ] [1130 ] 275+855\n",
      "[583  ] [583  ] 291+292\n",
      "[1135 ] [1135 ] 577+558\n",
      "[1553 ] [1552 ] 837+716\n",
      "[687  ] [687  ] 170+517\n",
      "[1025 ] [1025 ] 535+490\n",
      "[1123 ] [1123 ] 336+787\n",
      "[852  ] [852  ] 444+408\n",
      "[1499 ] [1499 ] 683+816\n",
      "[985  ] [985  ] 698+287\n",
      "[606  ] [606  ] 465+141\n",
      "[618  ] [618  ] 335+283\n",
      "errs: 0.16000\n"
     ]
    }
   ],
   "source": [
    "errs = []\n",
    "for _ in range(100):\n",
    "    expr, ans_ = make_random_data()\n",
    "    truth = (ans_+' ')[1:6]\n",
    "    ans, e_out  = infer(expr)\n",
    "    print('['+truth+']', '['+ans+']', expr)\n",
    "    errs.append(0 if truth == ans else 1)\n",
    "print('errs: {:.5f}'.format(np.mean(errs,dtype=np.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN activation visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.569Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5d7102b190>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAD8CAYAAAAsX4y/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlDF2rEREGWPHSkSUsf8Fcobqcegy90cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d73625850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(np.array(e_out.transpose() * 127 + 128,dtype=np.int32),\n",
    "           cmap='gray',\n",
    "           aspect=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logdir2/encoder_decoder/save'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(tf.get_default_session(), 'logdir2/encoder_decoder/save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1722\r\n",
      "-rwxrwxrwx 1 rhee users      65 Oct 11 10:55 checkpoint\r\n",
      "-rwxrwxrwx 1 rhee users  893811 Oct 11 10:54 events.out.tfevents.1507686474.rhee\r\n",
      "-rwxrwxrwx 1 rhee users 1254164 Oct 11 10:55 save.data-00000-of-00001\r\n",
      "-rwxrwxrwx 1 rhee users    1677 Oct 11 10:55 save.index\r\n",
      "-rwxrwxrwx 1 rhee users  505854 Oct 11 10:55 save.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l logdir2/encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-11T01:45:28.572Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess,tf.train.latest_checkpoint('logdir/rnn1'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
