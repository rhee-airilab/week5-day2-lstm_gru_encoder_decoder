{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN - Encoder-Decoder with `static_rnn()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -fr logdir3\n",
    "!mkdir -p logdir3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@media print {\n",
       "  a[href]:after {\n",
       "    content: none !important;\n",
       "  }\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext do_not_print_href\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-'\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data set - symbols & symbol map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# - 입력/출력 문자는 0~9 까지의 숫자,\n",
    "#   연산자 `'+'`, `' '` (END), `'='` (START) 포함하여 13 종류\n",
    "# - 사용가능한 연산자는 `'+'`\n",
    "# - 문자(symbol) 와 해당 문자의 인덱스 넘버 사이의 변환테이블들\n",
    "#   - `symbols[]`    : 인덱스에서 문자로\n",
    "#   - `symbol_map[]` : 문자에서 인덱스로\n",
    "\n",
    "symbols        = [' ', '0', '1', '2', '3', '4', '5',\n",
    "                  '6', '7', '8', '9', '+', '=']\n",
    "operators      = ['+']\n",
    "\n",
    "symbol_map     = {s: i \\\n",
    "                  for i,s in enumerate(symbols)}\n",
    "\n",
    "input_units    = output_units    = len(symbol_map)\n",
    "\n",
    "hidden_units   = 100\n",
    "\n",
    "encoder_max_seq_len = 7\n",
    "decoder_max_seq_len = 5\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "\n",
    "def make_random_data():\n",
    "    t1        = str(np.random.randint(1000))\n",
    "    op        = np.random.choice(operators)\n",
    "    t2        = str(np.random.randint(1000))\n",
    "    \n",
    "    expr      = t1 + op + t2\n",
    "    ans       = '='+str(eval(expr))+' '\n",
    "    \n",
    "    return expr, ans\n",
    "\n",
    "def one_hot(n):\n",
    "    \"\"\"\n",
    "    3 ==> [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \"\"\"\n",
    "    res = np.zeros(13, dtype=np.float32)\n",
    "    res[n] = 1.0\n",
    "    return res\n",
    "\n",
    "def arg_max(v):\n",
    "    \"\"\"\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] ==> 3\n",
    "    \"\"\"\n",
    "    return np.argmax(v, axis=-1)\n",
    "\n",
    "# test\n",
    "assert 7 == arg_max(one_hot(7))\n",
    "\n",
    "def str_to_onehot(str, max_seq_len):\n",
    "    buf           = np.zeros([max_seq_len,input_units])\n",
    "    buf          += \\\n",
    "      one_hot(symbol_map[' ']).reshape([1,-1]) # <<<===\n",
    "    seq_len       = len(str)\n",
    "    buf[:seq_len] = [one_hot(symbol_map[c]) for c in str]\n",
    "    return buf\n",
    "\n",
    "def onehot_to_str(data, data_len):\n",
    "    return ''.join([symbols[v] \\\n",
    "                    for v in arg_max(data)][:data_len])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def encode_data(expr, ans):\n",
    "    e_seq_len         = len(expr)\n",
    "    e_in              = str_to_onehot(expr,\n",
    "                                      encoder_max_seq_len)\n",
    "    d_seq_len         = len(ans) - 1\n",
    "    d_in              = str_to_onehot(ans[:-1],\n",
    "                                      decoder_max_seq_len)\n",
    "    d_out             = str_to_onehot(ans[1:],\n",
    "                                      decoder_max_seq_len)\n",
    "    return e_seq_len, e_in, d_seq_len, d_in, d_out\n",
    "\n",
    "def decode_data(e_len, e_in, d_len, d_in, d_out):\n",
    "    return  e_len, \\\n",
    "            onehot_to_str(e_in, e_len), \\\n",
    "            d_len, \\\n",
    "            onehot_to_str(d_in, d_len), \\\n",
    "            onehot_to_str(d_out, d_len)\n",
    "\n",
    "            \n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.encoder_seq_len  = []\n",
    "        self.encoder_in_data  = []\n",
    "        self.decoder_seq_len  = []\n",
    "        self.decoder_in_data  = []\n",
    "        self.decoder_out_data = []\n",
    "        \n",
    "    def append(self, t):\n",
    "        self.encoder_seq_len.append(t[0])\n",
    "        self.encoder_in_data.append(t[1])\n",
    "        self.decoder_seq_len.append(t[2])\n",
    "        self.decoder_in_data.append(t[3])\n",
    "        self.decoder_out_data.append(t[4])\n",
    "        \n",
    "    def next_batch(self,batch_size=BATCH_SIZE):\n",
    "        data_len = len(self.encoder_seq_len)\n",
    "        batch_pointer = 0\n",
    "        while batch_pointer + batch_size <= data_len:\n",
    "            ss   = np.random.randint(\n",
    "                data_len - batch_size - 1)\n",
    "            yield \\\n",
    "                self.encoder_seq_len[ss:ss+batch_size], \\\n",
    "                self.encoder_in_data[ss:ss+batch_size], \\\n",
    "                self.decoder_seq_len[ss:ss+batch_size], \\\n",
    "                self.decoder_in_data[ss:ss+batch_size], \\\n",
    "                self.decoder_out_data[ss:ss+batch_size]\n",
    "            batch_pointer += batch_size\n",
    "\n",
    "    def get(self, index):\n",
    "        return \\\n",
    "            self.encoder_seq_len[index], \\\n",
    "            self.encoder_in_data[index], \\\n",
    "            self.decoder_seq_len[index], \\\n",
    "            self.decoder_in_data[index], \\\n",
    "            self.decoder_out_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num_data = 60000\n",
    "test_num_data  = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(37L)\n",
    "\n",
    "train_data = Dataset()\n",
    "for i in range(train_num_data):\n",
    "    expr, ans     = make_random_data()\n",
    "    train_data.append(encode_data(expr, ans))\n",
    "\n",
    "test_data  = Dataset()\n",
    "for i in range(test_num_data):\n",
    "    expr, ans     = make_random_data()\n",
    "    test_data.append(encode_data(expr, ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, '756+55', 4, '=811', '811 ')\n",
      "(7, '269+927', 5, '=1196', '1196 ')\n",
      "(7, '208+259', 4, '=467', '467 ')\n",
      "(7, '529+653', 5, '=1182', '1182 ')\n",
      "(7, '928+119', 5, '=1047', '1047 ')\n",
      "(7, '811+285', 5, '=1096', '1096 ')\n",
      "(7, '713+889', 5, '=1602', '1602 ')\n",
      "(7, '866+703', 5, '=1569', '1569 ')\n",
      "(7, '868+410', 5, '=1278', '1278 ')\n",
      "(7, '790+602', 5, '=1392', '1392 ')\n"
     ]
    }
   ],
   "source": [
    "e_len,e_in,d_len,d_in,d_out = train_data.next_batch().next()\n",
    "for i in range(10):\n",
    "    print(decode_data(e_len[i],e_in[i],d_len[i],d_in[i],d_out[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow - build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow - placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs   = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, encoder_max_seq_len, input_units],\n",
    "    name='encoder_inputs')\n",
    "encoder_seqlen   = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=[None],\n",
    "    name='encoder_seqlen')\n",
    "decoder_inputs   = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, decoder_max_seq_len, input_units],\n",
    "    name='decoder_inputs')\n",
    "decoder_targets  = tf.placeholder(\n",
    "    dtype=tf.float32,\n",
    "    shape=[None, decoder_max_seq_len, output_units],\n",
    "    name='decoder_targets')\n",
    "decoder_seqlen   = tf.placeholder(\n",
    "    dtype=tf.int32,\n",
    "    shape=[None],\n",
    "    name='decoder_seqlen')\n",
    "encoder_training = tf.placeholder(\n",
    "    dtype=tf.bool,\n",
    "    shape=None,\n",
    "    name='encoder_training')\n",
    "tf_batch_size = tf.shape(encoder_inputs)[0] # <<== !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "keep_prob = tf.cond(encoder_training,\n",
    "                    lambda: tf.constant(1.0-dropout_rate),\n",
    "                    lambda: tf.constant(1.0),\n",
    "                    name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN, Encoder/Decoder - using `static_rnn()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- legacy_seq2seq 모듈 아래 메소드들은 입력데이터 포맷 요구 사항이 dynamic_rnn 때와 다름\n",
    "\n",
    "\n",
    "- dynamic_rnn: (default)\n",
    "    \n",
    "  - <span style=\"color:red\">Tensor</span> of shape: [batch_size, max_seq_len, num_units]\n",
    "\n",
    "\n",
    "- legacy_seqseq:\n",
    "    \n",
    "  - <span style=\"color:red\">List</span> of tensors of shape: [batch_size, num_units]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _batch-major_ to _time-major_\n",
    "\n",
    "- [`tf.unstack()`](http://devdocs.io/tensorflow~python/tf/unstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.,   1.,   2.,   3.],\n",
       "        [  4.,   5.,   6.,   7.],\n",
       "        [  8.,   9.,  10.,  11.]],\n",
       "\n",
       "       [[ 12.,  13.,  14.,  15.],\n",
       "        [ 16.,  17.,  18.,  19.],\n",
       "        [ 20.,  21.,  22.,  23.]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = tf.ConfigProto(gpu_options={'per_process_gpu_memory_fraction': 0.0})\n",
    "sess  = tf.InteractiveSession(config=config)\n",
    "\n",
    "# b_maj : batch_size = 2, max_seq_len = 3, num_units = 4\n",
    "b_maj = tf.reshape(tf.range(24,dtype=tf.float32),[2,3,4])\n",
    "b_maj.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'unstack:0' shape=(2, 4) dtype=float32>,\n",
       " <tf.Tensor 'unstack:1' shape=(2, 4) dtype=float32>,\n",
       " <tf.Tensor 'unstack:2' shape=(2, 4) dtype=float32>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_maj = tf.unstack(b_maj,3,1)\n",
    "t_maj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  0.,   1.,   2.,   3.],\n",
       "        [ 12.,  13.,  14.,  15.]], dtype=float32),\n",
       " array([[  4.,   5.,   6.,   7.],\n",
       "        [ 16.,  17.,  18.,  19.]], dtype=float32),\n",
       " array([[  8.,   9.,  10.,  11.],\n",
       "        [ 20.,  21.,  22.,  23.]], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.eval() for t in t_maj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _time-major_ to _batch-major_\n",
    "\n",
    "- [`tf.stack()`](http://devdocs.io/tensorflow~python/tf/stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.,   1.,   2.,   3.],\n",
       "        [  4.,   5.,   6.,   7.],\n",
       "        [  8.,   9.,  10.,  11.]],\n",
       "\n",
       "       [[ 12.,  13.,  14.,  15.],\n",
       "        [ 16.,  17.,  18.,  19.],\n",
       "        [ 20.,  21.,  22.,  23.]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_maj_again = tf.stack(t_maj, 1)\n",
    "b_maj_again.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _batch-major_ input/output 에 _time-major_ rnn 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [batch_size, max_seq_len, num_units] 형태의 tensor들을\n",
    "# list of [batch_size, num_units] 형태로 바꿔야 한다.\n",
    "# (batch-major to time-major)\n",
    "\n",
    "with tf.name_scope('encoder_input_transform'):\n",
    "    e_inputs   = tf.unstack(\n",
    "        encoder_inputs,\n",
    "        encoder_max_seq_len,\n",
    "        1,\n",
    "        name='transformed_encoder_inputs')\n",
    "    # shape: list of ([batch_size, num_units])\n",
    "\n",
    "with tf.name_scope('decoder_input_transform'):\n",
    "    d_inputs   = tf.unstack(\n",
    "        decoder_inputs,\n",
    "        decoder_max_seq_len,\n",
    "        1,\n",
    "        name='transformed_decoder_inputs')\n",
    "    # shape: list of ([batch_size, num_units])\n",
    "\n",
    "# tf.contrib.legacy_seq2seq.basic_rnn_seq2seq 를\n",
    "# 쓸 수 없음:\n",
    "#   - decoder state 를 줄 수 없음\n",
    "#   - training/inference 모드를 지정할 수 없음\n",
    "\n",
    "# dec_outs_, state = \\\n",
    "#     tf.contrib.legacy_seq2seq.basic_rnn_seq2seq(\n",
    "#         e_inputs,\n",
    "#         d_inputs,\n",
    "#         cell,\n",
    "#         dtype=tf.float32)\n",
    "\n",
    "def e_cell(input_size):\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LSTMCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LayerNormBasicLSTMCell(\n",
    "#              hidden_units)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        cell,\n",
    "        state_keep_prob = keep_prob,\n",
    "        variational_recurrent = True,\n",
    "        input_size = input_size,\n",
    "        dtype = tf.float32)\n",
    "    return cell\n",
    "\n",
    "with tf.variable_scope('encoder'):\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(\n",
    "        [\n",
    "            e_cell(input_units),\n",
    "            e_cell(hidden_units),\n",
    "            e_cell(hidden_units)\n",
    "        ])\n",
    "    initial_state = cell.zero_state(\n",
    "        batch_size=tf_batch_size,\n",
    "        dtype=tf.float32)\n",
    "    enc_outs_, encoder_state = \\\n",
    "        tf.nn.static_rnn(\n",
    "            cell,\n",
    "            e_inputs,\n",
    "            initial_state=initial_state,\n",
    "            sequence_length=encoder_seqlen,\n",
    "            dtype=tf.float32)\n",
    "\n",
    "def d_cell():\n",
    "    cell = tf.contrib.rnn.BasicRNNCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LSTMCell(hidden_units)\n",
    "#     cell = tf.contrib.rnn.LayerNormBasicLSTMCell(\n",
    "#              hidden_units)\n",
    "    return cell\n",
    "\n",
    "with tf.variable_scope('decoder'):\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(\n",
    "        [d_cell() for _ in range(3)])\n",
    "    dec_outs_, decoder_state = \\\n",
    "        tf.nn.static_rnn(\n",
    "            cell,\n",
    "            d_inputs,\n",
    "            initial_state=encoder_state,\n",
    "            sequence_length=decoder_seqlen,\n",
    "            dtype=tf.float32)\n",
    "\n",
    "# outputs 에 대해서는 위 inputs 들에 대한 변환의 역변환\n",
    "# (time-major to batch-major)\n",
    "encoder_out = \\\n",
    "    tf.stack(enc_outs_, 1, name='encoder_outputs')\n",
    "decoder_out = \\\n",
    "    tf.stack(dec_outs_, 1, name='decoder_outputs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 5, 100]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out.shape.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Network after RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = tf.layers.dense(\n",
    "    decoder_out,\n",
    "    output_units,\n",
    "    name='seq2seq_outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare training target vs output, do optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_mask_ = tf.sequence_mask(\n",
    "                decoder_seqlen,\n",
    "                maxlen=decoder_max_seq_len,\n",
    "                dtype=tf.float32)\n",
    "\n",
    "seq_mask  = \\\n",
    "    tf.tile(\n",
    "        tf.reshape(\n",
    "            seq_mask_,\n",
    "            [-1,decoder_max_seq_len,1]),\n",
    "        [1,1,output_units])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss         = tf.losses.softmax_cross_entropy(\n",
    "                    decoder_targets * seq_mask,\n",
    "                    outputs * seq_mask)\n",
    "\n",
    "optimizer    = tf.train.AdamOptimizer( \\\n",
    "                  learning_rate=0.001)\n",
    "optimize     = optimizer.minimize(\n",
    "    loss,\n",
    "    name='minimize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_equals(a,b,a_len=None,b_len=None):\n",
    "    if a_len is None: a_len = len(a)\n",
    "    if b_len is None: b_len = len(b)\n",
    "    a_nums = np.argmax(a[:a_len],-1)\n",
    "    b_nums = np.argmax(b[:b_len],-1)\n",
    "    return 1.0 * np.all(np.equal(a_nums, b_nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, writer):\n",
    "    t_start = time.time()\n",
    "    step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        losses  = []\n",
    "        errs    = []\n",
    "        for e_len, e_in, d_len, d_in, d_out \\\n",
    "                in train_data.next_batch():\n",
    "            feed = {\n",
    "                encoder_training: True,\n",
    "                encoder_seqlen:   e_len,\n",
    "                encoder_inputs:   e_in,\n",
    "                decoder_seqlen:   d_len,\n",
    "                decoder_inputs:   d_in,\n",
    "                decoder_targets:  d_out,\n",
    "            }\n",
    "            _, out, training_loss = \\\n",
    "                sess.run([optimize, outputs, loss], feed)\n",
    "            training_err = 1.0 - \\\n",
    "                np.mean([\n",
    "                    seq_equals(a,b,a_len,b_len)\n",
    "                    for a,b,a_len,b_len in\n",
    "                    zip(d_out,out,d_len,d_len)\n",
    "                ])\n",
    "            losses.append(training_loss)\n",
    "            errs.append(training_err)\n",
    "        test_errs   = []\n",
    "        for e_len, e_in, d_len, d_in, d_out \\\n",
    "                in test_data.next_batch():\n",
    "            feed = {\n",
    "                encoder_training: False,\n",
    "                encoder_seqlen:   e_len,\n",
    "                encoder_inputs:   e_in,\n",
    "                decoder_seqlen:   d_len,\n",
    "                decoder_inputs:   d_in,\n",
    "                decoder_targets:  d_out,\n",
    "            }\n",
    "            out, = sess.run([outputs], feed)\n",
    "            test_err = 1.0 - \\\n",
    "                np.mean([\n",
    "                    seq_equals(a,b,a_len,b_len)\n",
    "                    for a,b,a_len,b_len in\n",
    "                    zip(d_out,out,d_len,d_len)\n",
    "                ])\n",
    "            test_errs.append(test_err)\n",
    "        mean_loss       = np.mean(losses)\n",
    "        mean_err        = np.mean(errs)\n",
    "        mean_test_err   = np.mean(test_errs)\n",
    "        summary = tf.Summary(\n",
    "            value=[\n",
    "                tf.Summary.Value(\n",
    "                    tag='loss',\n",
    "                    simple_value=mean_loss),\n",
    "                tf.Summary.Value(\n",
    "                    tag='train_err',\n",
    "                    simple_value=mean_err),\n",
    "                tf.Summary.Value(\n",
    "                    tag='test_err',\n",
    "                    simple_value=mean_test_err),\n",
    "            ])\n",
    "        writer.add_summary(summary,epoch+1)\n",
    "        if 0 == (epoch+1) % 10:\n",
    "            t_elapsed = time.time() - t_start\n",
    "            print(('epoch: {:d}, loss: {:.5f}, ' +\n",
    "                   'err: {:.5f}, test_err: {:.5f}, ' +\n",
    "                   'elapsed: {:.2f}').format(\n",
    "                epoch+1,\n",
    "                mean_loss,\n",
    "                mean_err,\n",
    "                mean_test_err,\n",
    "                t_elapsed))\n",
    "            t_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_config   = tf.ConfigProto(\n",
    "    allow_soft_placement=True,\n",
    "    gpu_options={'allow_growth': True})\n",
    "sess        = tf.InteractiveSession(config=tf_config)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "writer      = tf.summary.FileWriter( \\\n",
    "           'logdir3/encoder_decoder',\n",
    "           tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.79396, err: 0.92645, test_err: 0.78910, elapsed: 31.96\n",
      "epoch: 20, loss: 0.46629, err: 0.68028, test_err: 0.37710, elapsed: 31.15\n",
      "epoch: 30, loss: 0.37138, err: 0.57937, test_err: 0.23600, elapsed: 31.06\n",
      "epoch: 40, loss: 0.31004, err: 0.49672, test_err: 0.25150, elapsed: 29.97\n",
      "epoch: 50, loss: 0.26574, err: 0.43688, test_err: 0.27790, elapsed: 35.21\n",
      "epoch: 60, loss: 0.22741, err: 0.37223, test_err: 0.22680, elapsed: 33.87\n",
      "epoch: 70, loss: 0.20682, err: 0.34608, test_err: 0.28190, elapsed: 49.75\n",
      "epoch: 80, loss: 0.18469, err: 0.30578, test_err: 0.23730, elapsed: 51.41\n",
      "epoch: 90, loss: 0.18562, err: 0.31292, test_err: 0.16370, elapsed: 49.72\n",
      "epoch: 100, loss: 0.17146, err: 0.28697, test_err: 0.23330, elapsed: 51.18\n"
     ]
    }
   ],
   "source": [
    "train(100, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training progress was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !tensorboard --logdir logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine inference steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expr = '123+456'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_to_onehot(expr,encoder_max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# batch size == 1\n",
    "feed = {\n",
    "    encoder_inputs: [str_to_onehot(expr,encoder_max_seq_len)],\n",
    "    encoder_seqlen: [7],\n",
    "    encoder_training: False,\n",
    "}\n",
    "e_out, e_state, = sess.run(\n",
    "    [encoder_out, encoder_state,],\n",
    "    feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_inputs_ = [str_to_onehot('=',decoder_max_seq_len)]\n",
    "decoder_input_buf = np.zeros_like(decoder_inputs_)\n",
    "decoder_input_buf[:,0,:] = np.array(decoder_inputs_)[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['=', ' ', ' ', ' ', ' ']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(onehot_to_str(decoder_input_buf[0],5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collect_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer: step 0: ['=', ' ', ' ', ' ', ' '] ==> ['5', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "feed = {\n",
    "    encoder_state:  e_state,\n",
    "    decoder_inputs: decoder_input_buf,\n",
    "    decoder_seqlen: [1],\n",
    "}\n",
    "out, d_state      = \\\n",
    "    sess.run([outputs,decoder_state,], feed)\n",
    "out_decoded = onehot_to_str(out[0],5)\n",
    "collect_output.append(out_decoded[0])\n",
    "print('infer: step {}: {} ==> {}'.format(\n",
    "    i,\n",
    "    list(onehot_to_str(decoder_input_buf[0],5)),\n",
    "    list(out_decoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer: step 1: ['5', ' ', ' ', ' ', ' '] ==> ['1', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "decoder_input_buf[:,0,:] = out[:,0,:]\n",
    "i = 1\n",
    "feed = {\n",
    "    encoder_state:  d_state,\n",
    "    decoder_inputs: decoder_input_buf,\n",
    "    decoder_seqlen: [1],\n",
    "}\n",
    "out, d_state      = \\\n",
    "    sess.run([outputs,decoder_state,], feed)\n",
    "out_decoded = onehot_to_str(out[0],5)\n",
    "collect_output.append(out_decoded[0])\n",
    "print('infer: step {}: {} ==> {}'.format(\n",
    "    i,\n",
    "    list(onehot_to_str(decoder_input_buf[0],5)),\n",
    "    list(out_decoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer: step 2: ['1', ' ', ' ', ' ', ' '] ==> ['4', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "decoder_input_buf[:,0,:] = out[:,0,:]\n",
    "i = 2\n",
    "feed = {\n",
    "    encoder_state:  d_state,\n",
    "    decoder_inputs: decoder_input_buf,\n",
    "    decoder_seqlen: [1],\n",
    "}\n",
    "out, d_state      = \\\n",
    "    sess.run([outputs,decoder_state,], feed)\n",
    "out_decoded = onehot_to_str(out[0],5)\n",
    "collect_output.append(out_decoded[0])\n",
    "print('infer: step {}: {} ==> {}'.format(\n",
    "    i,\n",
    "    list(onehot_to_str(decoder_input_buf[0],5)),\n",
    "    list(out_decoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer: step 3: ['4', ' ', ' ', ' ', ' '] ==> ['1', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "decoder_input_buf[:,0,:] = out[:,0,:]\n",
    "i = 3\n",
    "feed = {\n",
    "    encoder_state:  d_state,\n",
    "    decoder_inputs: decoder_input_buf,\n",
    "    decoder_seqlen: [1],\n",
    "}\n",
    "out, d_state      = \\\n",
    "    sess.run([outputs,decoder_state,], feed)\n",
    "out_decoded = onehot_to_str(out[0],5)\n",
    "collect_output.append(out_decoded[0])\n",
    "print('infer: step {}: {} ==> {}'.format(\n",
    "    i,\n",
    "    list(onehot_to_str(decoder_input_buf[0],5)),\n",
    "    list(out_decoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer: step 4: ['1', ' ', ' ', ' ', ' '] ==> ['1', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "decoder_input_buf[:,0,:] = out[:,0,:]\n",
    "i = 4\n",
    "feed = {\n",
    "    encoder_state:  d_state,\n",
    "    decoder_inputs: decoder_input_buf,\n",
    "    decoder_seqlen: [1],\n",
    "}\n",
    "out, d_state      = \\\n",
    "    sess.run([outputs,decoder_state,], feed)\n",
    "out_decoded = onehot_to_str(out[0],5)\n",
    "collect_output.append(out_decoded[0])\n",
    "print('infer: step {}: {} ==> {}'.format(\n",
    "    i,\n",
    "    list(onehot_to_str(decoder_input_buf[0],5)),\n",
    "    list(out_decoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '1', '4', '1', '1']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer(expr):\n",
    "    # encoder\n",
    "    feed = {\n",
    "        encoder_seqlen: [len(expr)],\n",
    "        encoder_inputs: \\\n",
    "            [str_to_onehot(expr,encoder_max_seq_len)],\n",
    "        encoder_training: False\n",
    "    }\n",
    "    e_out, e_state = \\\n",
    "        sess.run([encoder_out, encoder_state], feed)\n",
    "    \n",
    "    # decoder: step 0\n",
    "    out_buf = []\n",
    "    feed = {\n",
    "        encoder_state: e_state,\n",
    "        decoder_seqlen: [1],\n",
    "        decoder_inputs: \\\n",
    "            [str_to_onehot('=',decoder_max_seq_len)]\n",
    "    }\n",
    "    out, d_state = sess.run([outputs, decoder_state], feed)\n",
    "    out_decoded = onehot_to_str(out[0],1)\n",
    "    out_buf.append(out_decoded)\n",
    "    \n",
    "    # decoder: step 1..n-1\n",
    "    for _ in range(1,decoder_max_seq_len):\n",
    "        feed = {\n",
    "            encoder_state: d_state,\n",
    "            decoder_seqlen: [1],\n",
    "            decoder_inputs: \\\n",
    "                [str_to_onehot(out_decoded,decoder_max_seq_len)]\n",
    "        }\n",
    "        out, d_state = sess.run([outputs, decoder_state], feed)\n",
    "        out_decoded = onehot_to_str(out[0],1)\n",
    "        out_buf.append(out_decoded)\n",
    "\n",
    "    return ''.join(out_buf), e_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'456  '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans, _ = infer('345+111')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'567  '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans, _ = infer('345+222')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'333  '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans, e_out = infer('111+222')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1088 '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans, e_out = infer('999+99')\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1541 ] [1551 ] 905+636\n",
      "[996  ] [996  ] 525+471\n",
      "[662  ] [662  ] 61+601\n",
      "[1016 ] [1015 ] 29+987\n",
      "[830  ] [820  ] 286+544\n",
      "[796  ] [796  ] 78+718\n",
      "[437  ] [447  ] 408+29\n",
      "[1422 ] [1422 ] 488+934\n",
      "[869  ] [858  ] 861+8\n",
      "[1237 ] [1237 ] 428+809\n",
      "errs: 0.50000\n"
     ]
    }
   ],
   "source": [
    "errs = []\n",
    "for _ in range(10):\n",
    "    expr, ans_ = make_random_data()\n",
    "    truth = (ans_+' ')[1:6]\n",
    "    ans, _  = infer(expr)\n",
    "    print('['+truth+']', '['+ans+']', expr)\n",
    "    errs.append(0 if truth == ans else 1)\n",
    "print('errs: {:.5f}'.format(np.mean(errs,dtype=np.float32)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
